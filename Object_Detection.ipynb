{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHmNMWKClXAU",
    "outputId": "d5de420d-9c27-4183-f591-edb4d9ce2299"
   },
   "outputs": [],
   "source": [
    "conda install -c conda-forge opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z39yOKkZGHi_"
   },
   "outputs": [],
   "source": [
    "# import openCv\n",
    "import cv2\n",
    "# import uuid\n",
    "import uuid\n",
    "# import operating system\n",
    "import os\n",
    "# import time\n",
    "import time\n",
    "# ignore warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gs5erVvADgLu"
   },
   "source": [
    "# 2. Define images to collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLTqQnB-csv4"
   },
   "outputs": [],
   "source": [
    "labels = ['thumbsup', 'thumbsdown', 'thankyou', 'livelong']\n",
    "labels = ['thankyou']\n",
    "number_img = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiRutO0rgN-Q",
    "outputId": "995677b4-fa24-4668-a634-a0f4e4f0cca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(number_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crLDzvlLG4zg"
   },
   "source": [
    "# 3. Setup Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "b-j4RSOaHBo0"
   },
   "outputs": [],
   "source": [
    "Images_paths = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2JkvFXUHZE8",
    "outputId": "af1bc2cc-85f6-4a5f-cd38-b2f98e2b5c4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/workspace/images/collectedimages\n"
     ]
    }
   ],
   "source": [
    "print(Images_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zxFtkFDfHeBG"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(Images_paths):\n",
    "    if os.name =='posix':\n",
    "        os.makedirs(Images_paths, exist_ok=True)\n",
    "    if os.name == 'nt':\n",
    "        os.makedirs(Images_paths, exist_ok=True)\n",
    "for label in labels:\n",
    "    path = os.path.join(Images_paths, label)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs (path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xPietxqJ1TC"
   },
   "source": [
    "# 4. Capture Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "NezoopMIIilp",
    "outputId": "de1f39e8-ecf8-4bcf-930d-c0a1891bd81d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1285.065] global /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_f6tvh9615u/croot/opencv-suite_1691620375715/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for thankyou\n",
      "collecting images 0\n",
      "collecting images 1\n",
      "collecting images 2\n",
      "collecting images 3\n",
      "collecting images 4\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    cap = cv2.VideoCapture(0) # connects to the webcap or capture device\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(number_img):\n",
    "        print('collecting images {}'.format(imgnum))\n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(Images_paths, label, label+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname,frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "4mbs9vnzIkPG",
    "outputId": "93e339fa-e237-4079-963f-7c5ad2e44f77"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJoUnnnh_nMv"
   },
   "source": [
    "# image labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda list | grep pyqt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELING_PATH = os.path.join('Tensorflow', 'labelimg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LABELING_PATH):\n",
    "    os.makedirs(LABELING_PATH)\n",
    "    !git clone https://github.com/tzutalin/labelimg {LABELING_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == \"posix\":\n",
    "    !cd {LABELING_PATH} && make qt5py3\n",
    "if os.name ==\"nt\":\n",
    "    !cd {LABELING_PATH} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancel creation.\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.3ccfdfda-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.3ccfdfda-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.3e0b763e-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.3e0b763e-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.70f4cf78-88be-11f0-8b4f-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.70f4cf78-88be-11f0-8b4f-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.3f46bebe-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.3f46bebe-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.72a16778-88be-11f0-8b4f-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.72a16778-88be-11f0-8b4f-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.73e058e2-88be-11f0-8b4f-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.73e058e2-88be-11f0-8b4f-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.751c50d0-88be-11f0-8b4f-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.751c50d0-88be-11f0-8b4f-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.76582d3e-88be-11f0-8b4f-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.76582d3e-88be-11f0-8b4f-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.34dbc0aa-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.34dbc0aa-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.339b6c2c-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.339b6c2c-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.388d7626-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.388d7626-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.36165f20-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.36165f20-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.2b98c52e-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.2b98c52e-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.2cdbc828-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.2cdbc828-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.2e1c4406-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.2e1c4406-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.2f58579c-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.2f58579c-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.29e13fea-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.29e13fea-87bf-11f0-9565-1094bbd0ecec.xml\n",
      "Image:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.29e13fea-87bf-11f0-9565-1094bbd0ecec.jpg -> Annotation:/Users/briankimanzi/Documents/programmingLanguages/PythonProgramming/JupyterAI-Clean/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.29e13fea-87bf-11f0-9565-1094bbd0ecec.xml\n"
     ]
    }
   ],
   "source": [
    "# opening the label image package\n",
    "!cd {LABELING_PATH} && python labelimg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_PATH = os.path.expanduser(\"~/Documents/programmingLanguages/PythonProgramming/ObjectDetection/Tensorflow\")  # goes to your Documents folder\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[\"PIPELINE_CONFIG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code makes the directories visible\n",
    "for path in paths.values():\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == \"posix\":\n",
    "            !mkdir -p {path}\n",
    "        if os.name == \"nt\":\n",
    "            !mkdir -p {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Download TF Models Pretrained Models from tensorflow Model Zoo and Install TFOD</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == \"nt\":\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 102570, done.\u001b[K\n",
      "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
      "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
      "remote: Total 102570 (delta 58), reused 38 (delta 36), pack-reused 102482 (from 3)\u001b[K\n",
      "Receiving objects: 100% (102570/102570), 642.78 MiB | 1.07 MiB/s, done.\n",
      "Resolving deltas: 100% (74073/74073), done.\n",
      "Updating files: 100% (3947/3947), done.\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "#     !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "!cd models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.11.0 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (2.11.0)\n",
      "Collecting protobuf==3.20.3\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: numpy==1.23.5 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from tensorflow==2.11.0) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from tensorflow==2.11.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from tensorflow==2.11.0) (25.9.23)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from tensorflow==2.11.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from tensorflow==2.11.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from tensorflow==2.11.0) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from tensorflow==2.11.0) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from tensorflow==2.11.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from tensorflow==2.11.0) (25.0)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Cannot install protobuf==3.20.3 and tensorflow==2.11.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    The user requested protobuf==3.20.3\n",
      "    tensorflow 2.11.0 depends on protobuf<3.20 and >=3.9.2\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "Requirement already satisfied: tf-slim in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (6.0.2)\n",
      "Requirement already satisfied: pycocotools in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (2.0.10)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from tf-slim) (2.3.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from pycocotools) (1.23.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/objectDetection/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# # Install Tensorflow Object Detection \n",
    "# if os.name=='posix':  \n",
    "#     !apt-get install protobuf-compiler\n",
    "#     !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "# if os.name=='nt':\n",
    "#     url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "#     wget.download(url)\n",
    "#     !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "#     !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "#     os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "#     !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "#     !cd Tensorflow/models/research/slim && pip install -e . \n",
    "\n",
    "!pip install tensorflow==2.11.0 protobuf==3.20.3 numpy==1.23.5\n",
    "!pip install tf-slim lxml pycocotools matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: object_detection/protos/*.proto\n",
      "cp: object_detection/packages/tf2/setup.py: No such file or directory\n",
      "\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Inside models/research/\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!python -m pip install .\n",
    "\n",
    "# VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'],'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# # verify installation\n",
    "# !python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "tar: Error opening archive: Failed to open 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "# !pip uninstall protobuf object-detection -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.11.0\n",
      "  Using cached tensorflow-2.11.0-cp310-cp310-macosx_10_14_x86_64.whl.metadata (3.1 kB)\n",
      "Collecting protobuf==3.19.6\n",
      "  Using cached protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
      "Collecting numpy==1.23.5\n",
      "  Using cached numpy-1.23.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.11.0)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.11.0)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow==2.11.0)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.11.0)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.11.0)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=2.9.0 (from tensorflow==2.11.0)\n",
      "  Using cached h5py-3.14.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.11.0)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.11.0)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting packaging (from tensorflow==2.11.0)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting setuptools (from tensorflow==2.11.0)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting six>=1.12.0 (from tensorflow==2.11.0)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.11.0)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow==2.11.0)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.11.0)\n",
      "  Using cached wrapt-1.17.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.11.0)\n",
      "  Using cached grpcio-1.75.1-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard<2.12,>=2.11 (from tensorflow==2.11.0)\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11.0)\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.12,>=2.11.0 (from tensorflow==2.11.0)\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.11.0)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel>=0.26 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
      "  Using cached markupsafe-3.0.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.7 kB)\n",
      "Using cached tensorflow-2.11.0-cp310-cp310-macosx_10_14_x86_64.whl (244.3 MB)\n",
      "Using cached protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
      "Using cached numpy-1.23.5-cp310-cp310-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Using cached grpcio-1.75.1-cp310-cp310-macosx_11_0_universal2.whl (11.5 MB)\n",
      "Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Using cached google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Using cached cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl (207 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached h5py-3.14.0-cp310-cp310-macosx_10_9_x86_64.whl (3.3 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl (26.5 MB)\n",
      "Using cached markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_10_14_x86_64.whl (2.5 MB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached markupsafe-3.0.3-cp310-cp310-macosx_10_9_x86_64.whl (11 kB)\n",
      "Using cached wrapt-1.17.3-cp310-cp310-macosx_10_9_x86_64.whl (38 kB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, opt-einsum, oauthlib, numpy, MarkupSafe, markdown, keras, idna, gast, charset_normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, h5py, grpcio, google-pasta, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "\u001b[2K  Attempting uninstall: tensorboard-plugin-wit\n",
      "\u001b[2K    Found existing installation: tensorboard-plugin-wit 1.8.1\n",
      "\u001b[2K    Uninstalling tensorboard-plugin-wit-1.8.1:\n",
      "\u001b[2K      Successfully uninstalled tensorboard-plugin-wit-1.8.1\n",
      "\u001b[2K  Attempting uninstall: libclang━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/41\u001b[0m [tensorboard-plugin-wit]\n",
      "\u001b[2K    Found existing installation: libclang 18.1.1━━\u001b[0m \u001b[32m 0/41\u001b[0m [tensorboard-plugin-wit]\n",
      "\u001b[2K    Uninstalling libclang-18.1.1:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/41\u001b[0m [tensorboard-plugin-wit]\n",
      "\u001b[2K      Successfully uninstalled libclang-18.1.1━━━━\u001b[0m \u001b[32m 0/41\u001b[0m [tensorboard-plugin-wit]\n",
      "\u001b[2K  Attempting uninstall: flatbuffers7m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/41\u001b[0m [libclang]\n",
      "\u001b[2K    Found existing installation: flatbuffers 25.9.23━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/41\u001b[0m [libclang]\n",
      "\u001b[2K    Uninstalling flatbuffers-25.9.23:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/41\u001b[0m [libclang]\n",
      "\u001b[2K      Successfully uninstalled flatbuffers-25.9.23━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/41\u001b[0m [libclang]\n",
      "\u001b[2K  Attempting uninstall: wrapt237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/41\u001b[0m [libclang]\n",
      "\u001b[2K    Found existing installation: wrapt 1.14.2━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/41\u001b[0m [libclang]\n",
      "\u001b[2K    Uninstalling wrapt-1.14.2:37m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/41\u001b[0m [libclang]\n",
      "\u001b[2K      Successfully uninstalled wrapt-1.14.2━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/41\u001b[0m [libclang]\n",
      "\u001b[2K  Attempting uninstall: wheel38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/41\u001b[0m [wrapt]\n",
      "\u001b[2K    Found existing installation: wheel 0.45.1m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/41\u001b[0m [wrapt]\n",
      "\u001b[2K    Uninstalling wheel-0.45.1:249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/41\u001b[0m [wrapt]\n",
      "\u001b[2K      Successfully uninstalled wheel-0.45.1[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/41\u001b[0m [wrapt]\n",
      "\u001b[2K  Attempting uninstall: urllib38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/41\u001b[0m [wheel]\n",
      "\u001b[2K    Found existing installation: urllib3 2.3.0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/41\u001b[0m [wheel]\n",
      "\u001b[2K    Uninstalling urllib3-2.3.0:249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/41\u001b[0m [wheel]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.3.0[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/41\u001b[0m [wheel]\n",
      "\u001b[2K  Attempting uninstall: typing-extensions8;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/41\u001b[0m [urllib3]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.12.27m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/41\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.12.2:m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/41\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.12.238;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/41\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: termcolor8;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/41\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: termcolor 3.1.0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/41\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling termcolor-3.1.0:249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/41\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled termcolor-3.1.0[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/41\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tensorflow-io-gcs-filesystem8;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/41\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/41\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/41\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/41\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tensorflow-estimator8;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/41\u001b[0m [tensorflow-io-gcs-filesystem]\n",
      "\u001b[2K    Found existing installation: tensorflow-estimator 2.12.07m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/41\u001b[0m [tensorflow-io-gcs-filesystem]\n",
      "\u001b[2K    Uninstalling tensorflow-estimator-2.12.0:m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/41\u001b[0m [tensorflow-io-gcs-filesystem]\n",
      "\u001b[2K      Successfully uninstalled tensorflow-estimator-2.12.0237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/41\u001b[0m [tensorflow-io-gcs-filesystem]\n",
      "\u001b[2K  Attempting uninstall: tensorboard-data-server114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/41\u001b[0m [tensorflow-estimator]tem]\n",
      "\u001b[2K    Found existing installation: tensorboard-data-server 0.7.25;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/41\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K    Uninstalling tensorboard-data-server-0.7.2:m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/41\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K      Successfully uninstalled tensorboard-data-server-0.7.2237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/41\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K  Attempting uninstall: six━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/41\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K    Found existing installation: six 1.17.0;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/41\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K    Uninstalling six-1.17.0:0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/41\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K      Successfully uninstalled six-1.17.0;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/41\u001b[0m [six]ard-data-server]\n",
      "\u001b[2K  Attempting uninstall: setuptools8;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/41\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: setuptools 80.9.0\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/41\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling setuptools-80.9.0:m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/41\u001b[0m [setuptools]\n",
      "\u001b[2K      Successfully uninstalled setuptools-80.9.08;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/41\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: pyasn1━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/41\u001b[0m [setuptools]\n",
      "\u001b[2K    Found existing installation: pyasn1 0.6.1;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/41\u001b[0m [setuptools]\n",
      "\u001b[2K    Uninstalling pyasn1-0.6.1:━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/41\u001b[0m [pyasn1]\n",
      "\u001b[2K      Successfully uninstalled pyasn1-0.6.1;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/41\u001b[0m [pyasn1]\n",
      "\u001b[2K  Attempting uninstall: protobuf━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/41\u001b[0m [pyasn1]\n",
      "\u001b[2K    Found existing installation: protobuf 4.25.814m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/41\u001b[0m [pyasn1]\n",
      "\u001b[2K    Uninstalling protobuf-4.25.8:\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/41\u001b[0m [pyasn1]\n",
      "\u001b[2K      Successfully uninstalled protobuf-4.25.849;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/41\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: packaging━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/41\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: packaging 24.2;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/41\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling packaging-24.2:0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/41\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled packaging-24.238;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/41\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: opt-einsum━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/41\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: opt_einsum 3.4.0114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/41\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling opt_einsum-3.4.0:m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/41\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled opt_einsum-3.4.08;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/41\u001b[0m [packaging]\n",
      "\u001b[2K  Attempting uninstall: oauthlib━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/41\u001b[0m [opt-einsum]\n",
      "\u001b[2K    Found existing installation: oauthlib 3.3.138;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/41\u001b[0m [opt-einsum]\n",
      "\u001b[2K    Uninstalling oauthlib-3.3.1:\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/41\u001b[0m [opt-einsum]\n",
      "\u001b[2K      Successfully uninstalled oauthlib-3.3.19;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/41\u001b[0m [opt-einsum]\n",
      "\u001b[2K  Attempting uninstall: numpy━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/41\u001b[0m [oauthlib]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/41\u001b[0m [oauthlib]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/41\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/41\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafe━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/41\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/41\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.2:━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/41\u001b[0m [MarkupSafe]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/41\u001b[0m [MarkupSafe]\n",
      "\u001b[2K  Attempting uninstall: markdown━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/41\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Found existing installation: Markdown 3.9;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/41\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Uninstalling Markdown-3.9:━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/41\u001b[0m [MarkupSafe]\n",
      "\u001b[2K      Successfully uninstalled Markdown-3.9;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/41\u001b[0m [MarkupSafe]\n",
      "\u001b[2K  Attempting uninstall: keras━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/41\u001b[0m [markdown]\n",
      "\u001b[2K    Found existing installation: keras 2.12.02;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/41\u001b[0m [markdown]\n",
      "\u001b[2K    Uninstalling keras-2.12.0:━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/41\u001b[0m [keras]kdown]\n",
      "\u001b[2K      Successfully uninstalled keras-2.12.038;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/41\u001b[0m [keras]\n",
      "\u001b[2K  Attempting uninstall: idna━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/41\u001b[0m [keras]\n",
      "\u001b[2K    Found existing installation: idna 3.7\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/41\u001b[0m [keras]\n",
      "\u001b[2K    Uninstalling idna-3.7:━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/41\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled idna-3.7[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/41\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: gast━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/41\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: gast 0.4.0[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/41\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling gast-0.4.0:━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/41\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled gast-0.4.0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/41\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: charset_normalizer━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/41\u001b[0m [gast]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.3.20m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/41\u001b[0m [gast]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.3.2:m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/41\u001b[0m [gast]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.3.2\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/41\u001b[0m [gast]\n",
      "\u001b[2K  Attempting uninstall: certifi━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/41\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: certifi 2025.8.35;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/41\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling certifi-2025.8.3:━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/41\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.8.38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/41\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: cachetools━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/41\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: cachetools 5.5.25;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/41\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling cachetools-5.5.2:━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/41\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled cachetools-5.5.2[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/41\u001b[0m [cachetools]zer]\n",
      "\u001b[2K  Attempting uninstall: absl-py━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/41\u001b[0m [cachetools]\n",
      "\u001b[2K    Found existing installation: absl-py 1.4.0\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/41\u001b[0m [cachetools]\n",
      "\u001b[2K    Uninstalling absl-py-1.4.0:━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/41\u001b[0m [cachetools]\n",
      "\u001b[2K      Successfully uninstalled absl-py-1.4.00m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/41\u001b[0m [cachetools]\n",
      "\u001b[2K  Attempting uninstall: werkzeug━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m27/41\u001b[0m [absl-py]\n",
      "\u001b[2K    Found existing installation: Werkzeug 3.1.3\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m27/41\u001b[0m [absl-py]\n",
      "\u001b[2K    Uninstalling Werkzeug-3.1.3:━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m28/41\u001b[0m [werkzeug]\n",
      "\u001b[2K      Successfully uninstalled Werkzeug-3.1.3━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m28/41\u001b[0m [werkzeug]\n",
      "\u001b[2K  Attempting uninstall: rsa━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m28/41\u001b[0m [werkzeug]\n",
      "\u001b[2K    Found existing installation: rsa 4.9.1━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m28/41\u001b[0m [werkzeug]\n",
      "\u001b[2K    Uninstalling rsa-4.9.1:━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m28/41\u001b[0m [werkzeug]\n",
      "\u001b[2K      Successfully uninstalled rsa-4.9.1━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m28/41\u001b[0m [werkzeug]\n",
      "\u001b[2K  Attempting uninstall: requests━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m29/41\u001b[0m [rsa]]\n",
      "\u001b[2K    Found existing installation: requests 2.32.4m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m29/41\u001b[0m [rsa]\n",
      "\u001b[2K    Uninstalling requests-2.32.4:━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m30/41\u001b[0m [requests]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.4\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m30/41\u001b[0m [requests]\n",
      "\u001b[2K  Attempting uninstall: pyasn1-modules━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m30/41\u001b[0m [requests]\n",
      "\u001b[2K    Found existing installation: pyasn1_modules 0.4.28;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m30/41\u001b[0m [requests]\n",
      "\u001b[2K    Uninstalling pyasn1_modules-0.4.2:━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m31/41\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K      Successfully uninstalled pyasn1_modules-0.4.2\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m31/41\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K  Attempting uninstall: h5py━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m31/41\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Found existing installation: h5py 3.14.0━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m31/41\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Uninstalling h5py-3.14.0:━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m31/41\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K      Successfully uninstalled h5py-3.14.0━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m31/41\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K  Attempting uninstall: grpcio━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m32/41\u001b[0m [h5py]dules]\n",
      "\u001b[2K    Found existing installation: grpcio 1.65.5━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m32/41\u001b[0m [h5py]\n",
      "\u001b[2K    Uninstalling grpcio-1.65.5:━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m33/41\u001b[0m [grpcio]\n",
      "\u001b[2K      Successfully uninstalled grpcio-1.65.5━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m33/41\u001b[0m [grpcio]\n",
      "\u001b[2K  Attempting uninstall: google-pasta━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m33/41\u001b[0m [grpcio]\n",
      "\u001b[2K    Found existing installation: google-pasta 0.2.00m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m33/41\u001b[0m [grpcio]\n",
      "\u001b[2K    Uninstalling google-pasta-0.2.0:━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[32m34/41\u001b[0m [google-pasta]\n",
      "\u001b[2K      Successfully uninstalled google-pasta-0.2.0\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m33/41\u001b[0m [grpcio]\n",
      "\u001b[2K  Attempting uninstall: astunparse━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[32m34/41\u001b[0m [google-pasta]\n",
      "\u001b[2K    Found existing installation: astunparse 1.6.3━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[32m34/41\u001b[0m [google-pasta]\n",
      "\u001b[2K    Uninstalling astunparse-1.6.3:━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m35/41\u001b[0m [astunparse]\n",
      "\u001b[2K      Successfully uninstalled astunparse-1.6.3━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m35/41\u001b[0m [astunparse]\n",
      "\u001b[2K  Attempting uninstall: requests-oauthlib━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m35/41\u001b[0m [astunparse]\n",
      "\u001b[2K    Found existing installation: requests-oauthlib 2.0.0[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m35/41\u001b[0m [astunparse]\n",
      "\u001b[2K    Uninstalling requests-oauthlib-2.0.0:━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━\u001b[0m \u001b[32m36/41\u001b[0m [requests-oauthlib]\n",
      "\u001b[2K      Successfully uninstalled requests-oauthlib-2.0.00m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━\u001b[0m \u001b[32m36/41\u001b[0m [requests-oauthlib]\n",
      "\u001b[2K  Attempting uninstall: google-auth━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━\u001b[0m \u001b[32m36/41\u001b[0m [requests-oauthlib]\n",
      "\u001b[2K    Found existing installation: google-auth 2.40.3━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m37/41\u001b[0m [google-auth]b]\n",
      "\u001b[2K    Uninstalling google-auth-2.40.3:━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m37/41\u001b[0m [google-auth]b]\n",
      "\u001b[2K      Successfully uninstalled google-auth-2.40.3━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m37/41\u001b[0m [google-auth]\n",
      "\u001b[2K  Attempting uninstall: google-auth-oauthlib━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m37/41\u001b[0m [google-auth]\n",
      "\u001b[2K    Found existing installation: google-auth-oauthlib 1.0.038;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m37/41\u001b[0m [google-auth]\n",
      "\u001b[2K    Uninstalling google-auth-oauthlib-1.0.0:━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m37/41\u001b[0m [google-auth]\n",
      "\u001b[2K      Successfully uninstalled google-auth-oauthlib-1.0.0\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m37/41\u001b[0m [google-auth]\n",
      "\u001b[2K  Attempting uninstall: tensorboard━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m38/41\u001b[0m [google-auth-oauthlib]\n",
      "\u001b[2K    Found existing installation: tensorboard 2.12.3━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m38/41\u001b[0m [google-auth-oauthlib]\n",
      "\u001b[2K    Uninstalling tensorboard-2.12.3:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m39/41\u001b[0m [tensorboard]hlib]\n",
      "\u001b[2K      Successfully uninstalled tensorboard-2.12.3━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m39/41\u001b[0m [tensorboard]\n",
      "\u001b[2K  Attempting uninstall: tensorflow━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m39/41\u001b[0m [tensorboard]\n",
      "\u001b[2K    Found existing installation: tensorflow 2.11.0━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m \u001b[32m40/41\u001b[0m [tensorflow]tensorboard]\n",
      "\u001b[2K    Uninstalling tensorflow-2.11.0:━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m \u001b[32m40/41\u001b[0m [tensorflow]\n",
      "\u001b[2K      Successfully uninstalled tensorflow-2.11.0━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m \u001b[32m40/41\u001b[0m [tensorflow]\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/41\u001b[0m [tensorflow]0m [tensorflow]\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.68.0 requires grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1; python_version <= \"3.12\", but you have grpcio 1.75.1 which is incompatible.\n",
      "apache-beam 2.68.0 requires protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
      "googleapis-common-protos 1.70.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-datasets 4.9.9 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-macos 2.12.0 requires keras<2.13,>=2.12.0, but you have keras 2.11.0 which is incompatible.\n",
      "tensorflow-macos 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-macos 2.12.0 requires tensorboard<2.13,>=2.12, but you have tensorboard 2.11.2 which is incompatible.\n",
      "tensorflow-macos 2.12.0 requires tensorflow-estimator<2.13,>=2.12.0, but you have tensorflow-estimator 2.11.0 which is incompatible.\n",
      "tensorflow-macos 2.12.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.17.3 which is incompatible.\n",
      "tensorflow-metadata 1.17.2 requires protobuf<4.22,>=4.21.6; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-model-optimization 0.8.0 requires absl-py~=1.2, but you have absl-py 2.3.1 which is incompatible.\n",
      "tensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.11.0 which is incompatible.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.11.0 which is incompatible.\n",
      "tf-models-official 2.16.0 requires tensorflow~=2.16.1, but you have tensorflow 2.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 absl-py-2.3.1 astunparse-1.6.3 cachetools-6.2.0 certifi-2025.10.5 charset_normalizer-3.4.3 flatbuffers-25.9.23 gast-0.4.0 google-auth-2.41.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.75.1 h5py-3.14.0 idna-3.10 keras-2.11.0 libclang-18.1.1 markdown-3.9 numpy-1.23.5 oauthlib-3.3.1 opt-einsum-3.4.0 packaging-25.0 protobuf-3.19.6 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-2.32.5 requests-oauthlib-2.0.0 rsa-4.9.1 setuptools-80.9.0 six-1.17.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0 typing-extensions-4.15.0 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.11.0 protobuf==3.19.6 numpy==1.23.5 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protobuf                  3.20.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: =2.11.0 not found\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow ==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mobject_detection\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 04:24:06.639126: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Object_Detection)",
   "language": "python",
   "name": "object_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
